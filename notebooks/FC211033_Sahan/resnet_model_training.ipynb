{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08797bd4",
   "metadata": {},
   "source": [
    "# ResNet-18 Emotion Recognition Model Training\n",
    "\n",
    "This notebook implements a ResNet-18 model for emotion recognition with professional training pipeline and visualization.\n",
    "\n",
    "## Features:\n",
    "- ResNet-18 architecture with custom classifier head\n",
    "- Advanced data augmentation\n",
    "- Mixed precision training\n",
    "- Professional visualization\n",
    "- Model checkpointing and early stopping\n",
    "\n",
    "**Author:** FC211033 Sahan  \n",
    "**Date:** July 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33644f5b",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1316e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "CUDA Memory: 4.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for professional plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a73fd",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7266dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "----------------------------------------\n",
      "data_path      : ../../data/processed/FC211033_Sahan\n",
      "save_dir       : ./models\n",
      "image_size     : 64\n",
      "batch_size     : 32\n",
      "num_workers    : 0\n",
      "epochs         : 25\n",
      "learning_rate  : 0.001\n",
      "weight_decay   : 0.0001\n",
      "patience       : 8\n",
      "num_classes    : 5\n",
      "dropout_rate   : 0.3\n",
      "label_smoothing: 0.1\n",
      "mixup_alpha    : 0.2\n",
      "train_split    : 0.8\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'data_path': '../../data/processed/FC211033_Sahan',\n",
    "    'save_dir': './models',\n",
    "    'image_size': 64,\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 0,  # Set to 0 for Windows compatibility\n",
    "    'epochs': 25,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 8,\n",
    "    'num_classes': 5,\n",
    "    'dropout_rate': 0.3,\n",
    "    'label_smoothing': 0.1,\n",
    "    'mixup_alpha': 0.2,\n",
    "    'train_split': 0.8  # 80% for training, 20% for validation\n",
    "}\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(CONFIG['save_dir'], exist_ok=True)\n",
    "\n",
    "# Print configuration\n",
    "print(\"Configuration:\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key:15}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdc616",
   "metadata": {},
   "source": [
    "## 3. Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9c6428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ..\\..\\data\\processed\\FC211033_Sahan\n",
      "Expected emotions: ['angry', 'happy', 'neutral', 'sad', 'surprise']\n",
      "\n",
      "Checking: ..\\..\\data\\processed\\FC211033_Sahan\\angry\n",
      "  Found 3983 image files\n",
      "\n",
      "Checking: ..\\..\\data\\processed\\FC211033_Sahan\\happy\n",
      "  Found 7210 image files\n",
      "\n",
      "Checking: ..\\..\\data\\processed\\FC211033_Sahan\\neutral\n",
      "  Found 4959 image files\n",
      "\n",
      "Checking: ..\\..\\data\\processed\\FC211033_Sahan\\sad\n",
      "  Found 4826 image files\n",
      "\n",
      "Checking: ..\\..\\data\\processed\\FC211033_Sahan\\surprise\n",
      "  Found 3165 image files\n",
      "\n",
      "Total samples loaded: 24143\n",
      "Class distribution:\n",
      "  angry   : 3983 ( 16.5%)\n",
      "  happy   : 7210 ( 29.9%)\n",
      "  neutral : 4959 ( 20.5%)\n",
      "  sad     : 4826 ( 20.0%)\n",
      "  surprise: 3165 ( 13.1%)\n",
      "\n",
      "Data split:\n",
      "  Training:   19314 samples (80.0%)\n",
      "  Validation: 4829 samples (20.0%)\n",
      "\n",
      "Updated num_classes to: 5\n",
      "Emotion classes: ['angry', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Professional emotion dataset with advanced augmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "        \n",
    "        print(f\"Dataset created with {len(self.data_list)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data_list[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(item['path'], cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            raise RuntimeError(f\"Could not load image: {item['path']}\")\n",
    "            \n",
    "        image = cv2.resize(image, (CONFIG['image_size'], CONFIG['image_size']))\n",
    "        image = Image.fromarray(image).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, item['label']\n",
    "\n",
    "def load_emotion_data(data_path):\n",
    "    \"\"\"Load all emotion data and create train/validation splits.\"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    # Define emotion classes - updated to match actual data structure\n",
    "    emotions = ['angry', 'happy', 'neutral', 'sad', 'surprise']\n",
    "    class_to_idx = {emotion: idx for idx, emotion in enumerate(emotions)}\n",
    "    \n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "    print(f\"Expected emotions: {emotions}\")\n",
    "    \n",
    "    all_data = []\n",
    "    class_counts = {emotion: 0 for emotion in emotions}\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        emotion_path = data_path / emotion\n",
    "        print(f\"\\nChecking: {emotion_path}\")\n",
    "        \n",
    "        if emotion_path.exists():\n",
    "            # Try different image extensions\n",
    "            image_files = []\n",
    "            for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "                image_files.extend(list(emotion_path.glob(ext)))\n",
    "            \n",
    "            print(f\"  Found {len(image_files)} image files\")\n",
    "            \n",
    "            for img_path in image_files:\n",
    "                all_data.append({\n",
    "                    'path': str(img_path),\n",
    "                    'label': class_to_idx[emotion],\n",
    "                    'emotion': emotion\n",
    "                })\n",
    "                class_counts[emotion] += 1\n",
    "        else:\n",
    "            print(f\"  ‚ùå Directory not found: {emotion_path}\")\n",
    "    \n",
    "    print(f\"\\nTotal samples loaded: {len(all_data)}\")\n",
    "    print(\"Class distribution:\")\n",
    "    for emotion, count in class_counts.items():\n",
    "        if len(all_data) > 0:\n",
    "            percentage = (count / len(all_data)) * 100\n",
    "            print(f\"  {emotion:8}: {count:4d} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    if len(all_data) == 0:\n",
    "        raise RuntimeError(\"No data found! Please check the data path and structure.\")\n",
    "    \n",
    "    # Shuffle data\n",
    "    np.random.shuffle(all_data)\n",
    "    \n",
    "    # Split into train and validation\n",
    "    split_idx = int(len(all_data) * CONFIG['train_split'])\n",
    "    train_data = all_data[:split_idx]\n",
    "    val_data = all_data[split_idx:]\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"  Training:   {len(train_data)} samples ({len(train_data)/len(all_data)*100:.1f}%)\")\n",
    "    print(f\"  Validation: {len(val_data)} samples ({len(val_data)/len(all_data)*100:.1f}%)\")\n",
    "    \n",
    "    return train_data, val_data, emotions, class_to_idx\n",
    "\n",
    "# Load the data\n",
    "train_data, val_data, emotion_classes, class_to_idx = load_emotion_data(CONFIG['data_path'])\n",
    "\n",
    "# Update config with actual number of classes\n",
    "CONFIG['num_classes'] = len(emotion_classes)\n",
    "print(f\"\\nUpdated num_classes to: {CONFIG['num_classes']}\")\n",
    "print(f\"Emotion classes: {emotion_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758d0f5",
   "metadata": {},
   "source": [
    "## 4. Data Transforms and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3350d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring data structure in: ..\\..\\data\\processed\\FC211033_Sahan\n",
      "==================================================\n",
      "üìÅ angry/\n",
      "   (0 PNG files)\n",
      "üìÅ happy/\n",
      "   (0 PNG files)\n",
      "üìÅ neutral/\n",
      "   (0 PNG files)\n",
      "üìÅ sad/\n",
      "   (0 PNG files)\n",
      "üìÅ surprise/\n"
     ]
    }
   ],
   "source": [
    "def explore_data_structure(base_path):\n",
    "    \"\"\"Explore and print the data directory structure.\"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    print(f\"Exploring data structure in: {base_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not base_path.exists():\n",
    "        print(f\"‚ùå Base path does not exist: {base_path}\")\n",
    "        # Try alternative paths\n",
    "        alt_paths = [\n",
    "            Path(\"../../data/processed\"),\n",
    "            Path(\"../data/processed\"),\n",
    "            Path(\"./data/processed\"),\n",
    "            Path(\"data/processed\")\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nTrying alternative paths:\")\n",
    "        for alt_path in alt_paths:\n",
    "            if alt_path.exists():\n",
    "                print(f\"‚úÖ Found: {alt_path.absolute()}\")\n",
    "                explore_subdirs(alt_path)\n",
    "                return str(alt_path)\n",
    "            else:\n",
    "                print(f\"‚ùå Not found: {alt_path.absolute()}\")\n",
    "        return None\n",
    "    \n",
    "    explore_subdirs(base_path)\n",
    "    return str(base_path)\n",
    "\n",
    "def explore_subdirs(path, level=0):\n",
    "    \"\"\"Recursively explore subdirectories.\"\"\"\n",
    "    if level > 3:  # Limit depth\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        for item in sorted(path.iterdir()):\n",
    "            if item.is_dir():\n",
    "                indent = \"  \" * level\n",
    "                print(f\"{indent}üìÅ {item.name}/\")\n",
    "                \n",
    "                # Check for emotion folders\n",
    "                emotions = ['angry', 'happy', 'neutral', 'sad', 'stressed']\n",
    "                if item.name.lower() in emotions:\n",
    "                    png_files = list(item.glob('*.png'))\n",
    "                    print(f\"{indent}   ({len(png_files)} PNG files)\")\n",
    "                elif item.name in ['train', 'test', 'val', 'validation']:\n",
    "                    print(f\"{indent}   üìä Data split folder\")\n",
    "                    explore_subdirs(item, level + 1)\n",
    "                elif level < 2:\n",
    "                    explore_subdirs(item, level + 1)\n",
    "    except PermissionError:\n",
    "        print(f\"‚ùå Permission denied: {path}\")\n",
    "\n",
    "# Explore the data structure first\n",
    "correct_path = explore_data_structure(CONFIG['data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a3ade5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Dataset created with 19314 samples\n",
      "Dataset created with 4829 samples\n",
      "\n",
      "‚úÖ Data loaders created successfully:\n",
      "  Train samples: 19314\n",
      "  Val samples:   4829\n",
      "  Train batches: 604\n",
      "  Val batches:   151\n",
      "  Batch size:    32\n",
      "\n",
      "‚úÖ Sample batch loaded successfully:\n",
      "  Images shape: torch.Size([32, 3, 64, 64])\n",
      "  Labels shape: torch.Size([32])\n",
      "  Image range: [-2.118, 2.640]\n",
      "  Label range: [0, 4]\n",
      "\n",
      "‚úÖ Sample batch loaded successfully:\n",
      "  Images shape: torch.Size([32, 3, 64, 64])\n",
      "  Labels shape: torch.Size([32])\n",
      "  Image range: [-2.118, 2.640]\n",
      "  Label range: [0, 4]\n"
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets using the loaded data\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = EmotionDataset(train_data, train_transform)\n",
    "val_dataset = EmotionDataset(val_data, val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaders created successfully:\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Val samples:   {len(val_dataset)}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Batch size:    {CONFIG['batch_size']}\")\n",
    "\n",
    "# Test loading a sample batch\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"\\n‚úÖ Sample batch loaded successfully:\")\n",
    "    print(f\"  Images shape: {sample_batch[0].shape}\")\n",
    "    print(f\"  Labels shape: {sample_batch[1].shape}\")\n",
    "    print(f\"  Image range: [{sample_batch[0].min():.3f}, {sample_batch[0].max():.3f}]\")\n",
    "    print(f\"  Label range: [{sample_batch[1].min()}, {sample_batch[1].max()}]\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading sample batch: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b4a1d",
   "metadata": {},
   "source": [
    "## 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf38a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionResNet(nn.Module):\n",
    "    \"\"\"ResNet-18 based emotion recognition model.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=5, dropout_rate=0.3):\n",
    "        super(EmotionResNet, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet-18\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers for transfer learning\n",
    "        for param in list(self.backbone.parameters())[:-20]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Get feature size\n",
    "        feature_size = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace classifier head\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(feature_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Create model\n",
    "model = EmotionResNet(\n",
    "    num_classes=CONFIG['num_classes'], \n",
    "    dropout_rate=CONFIG['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "# Model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total parameters:     {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size:           {total_params * 4 / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba66118",
   "metadata": {},
   "source": [
    "## 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bac1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG['label_smoothing'])\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"Training components initialized:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Criterion:     CrossEntropyLoss (label_smoothing={CONFIG['label_smoothing']})\")\n",
    "print(f\"Optimizer:     AdamW (lr={CONFIG['learning_rate']}, wd={CONFIG['weight_decay']})\")\n",
    "print(f\"Scheduler:     CosineAnnealingWarmRestarts\")\n",
    "print(f\"Mixed Precision: Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0cbab",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd560203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Apply mixup data augmentation.\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Compute mixup loss.\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, epoch):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch:2d}')\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Apply mixup with probability\n",
    "        if np.random.random() < 0.5:\n",
    "            data, target_a, target_b, lam = mixup_data(data, target, CONFIG['mixup_alpha'])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = mixup_criterion(criterion, output, target_a, target_b, lam)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Calculate accuracy for mixup\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += (lam * predicted.eq(target_a).sum().float() + \n",
    "                       (1 - lam) * predicted.eq(target_b).sum().float()).item()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    \"\"\"Validate model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b43926",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \"\"\"Complete training loop with early stopping.\"\"\"\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, epoch\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # Print epoch summary\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"\\nEpoch {epoch:2d} Summary:\")\n",
    "        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
    "        print(f\"  LR:    {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        print(f\"  Time:  {epoch_time:.1f}s\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'config': CONFIG,\n",
    "                'history': history\n",
    "            }, os.path.join(CONFIG['save_dir'], 'best_resnet_model.pth'))\n",
    "            \n",
    "            print(f\"  >> New best validation accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  >> Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch} epochs\")\n",
    "            break\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time/60:.1f} minutes\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "# Start training\n",
    "training_history, best_accuracy = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b23d799",
   "metadata": {},
   "source": [
    "## 9. Professional Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ae42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_plots(history, best_acc):\n",
    "    \"\"\"Create professional training visualization.\"\"\"\n",
    "    \n",
    "    # Set up the figure with professional styling\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Color palette\n",
    "    colors = {\n",
    "        'train': '#2E86AB',\n",
    "        'val': '#A23B72',\n",
    "        'lr': '#F18F01',\n",
    "        'best': '#C73E1D'\n",
    "    }\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # 1. Loss curves\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(epochs, history['train_loss'], color=colors['train'], \n",
    "             linewidth=2.5, label='Training Loss', marker='o', markersize=4)\n",
    "    ax1.plot(epochs, history['val_loss'], color=colors['val'], \n",
    "             linewidth=2.5, label='Validation Loss', marker='s', markersize=4)\n",
    "    ax1.set_title('Training & Validation Loss', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    \n",
    "    # 2. Accuracy curves\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(epochs, history['train_acc'], color=colors['train'], \n",
    "             linewidth=2.5, label='Training Accuracy', marker='o', markersize=4)\n",
    "    ax2.plot(epochs, history['val_acc'], color=colors['val'], \n",
    "             linewidth=2.5, label='Validation Accuracy', marker='s', markersize=4)\n",
    "    \n",
    "    # Highlight best accuracy\n",
    "    best_epoch = np.argmax(history['val_acc']) + 1\n",
    "    ax2.axvline(x=best_epoch, color=colors['best'], linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax2.axhline(y=best_acc, color=colors['best'], linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax2.scatter([best_epoch], [best_acc], color=colors['best'], s=100, zorder=5)\n",
    "    ax2.annotate(f'Best: {best_acc:.2f}%\\nEpoch {best_epoch}', \n",
    "                xy=(best_epoch, best_acc), xytext=(best_epoch + 2, best_acc - 5),\n",
    "                fontsize=10, ha='left', va='top',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8),\n",
    "                arrowprops=dict(arrowstyle='->', color=colors['best']))\n",
    "    \n",
    "    ax2.set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.legend(frameon=True, fancybox=True, shadow=True)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    \n",
    "    # 3. Learning rate schedule\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(epochs, history['learning_rates'], color=colors['lr'], \n",
    "             linewidth=2.5, marker='o', markersize=4)\n",
    "    ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax3.set_xlabel('Epoch', fontsize=12)\n",
    "    ax3.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    \n",
    "    # 4. Training progress comparison\n",
    "    ax4 = fig.add_subplot(gs[1, :])\n",
    "    \n",
    "    # Normalize metrics for comparison\n",
    "    train_loss_norm = (np.array(history['train_loss']) - np.min(history['train_loss'])) / (np.max(history['train_loss']) - np.min(history['train_loss']))\n",
    "    val_loss_norm = (np.array(history['val_loss']) - np.min(history['val_loss'])) / (np.max(history['val_loss']) - np.min(history['val_loss']))\n",
    "    train_acc_norm = np.array(history['train_acc']) / 100\n",
    "    val_acc_norm = np.array(history['val_acc']) / 100\n",
    "    \n",
    "    ax4.fill_between(epochs, 0, train_loss_norm, alpha=0.3, color=colors['train'], label='Train Loss (norm)')\n",
    "    ax4.fill_between(epochs, 0, val_loss_norm, alpha=0.3, color=colors['val'], label='Val Loss (norm)')\n",
    "    ax4.plot(epochs, train_acc_norm, color=colors['train'], linewidth=3, label='Train Accuracy')\n",
    "    ax4.plot(epochs, val_acc_norm, color=colors['val'], linewidth=3, label='Val Accuracy')\n",
    "    \n",
    "    ax4.set_title('Training Progress Overview', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax4.set_xlabel('Epoch', fontsize=12)\n",
    "    ax4.set_ylabel('Normalized Metrics', fontsize=12)\n",
    "    ax4.legend(loc='center right', frameon=True, fancybox=True, shadow=True)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.spines['top'].set_visible(False)\n",
    "    ax4.spines['right'].set_visible(False)\n",
    "    \n",
    "    # 5. Training statistics\n",
    "    ax5 = fig.add_subplot(gs[2, :])\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    # Create statistics table\n",
    "    stats_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Best Validation Accuracy', f'{best_acc:.2f}%'],\n",
    "        ['Final Training Accuracy', f'{history[\"train_acc\"][-1]:.2f}%'],\n",
    "        ['Final Training Loss', f'{history[\"train_loss\"][-1]:.4f}'],\n",
    "        ['Final Validation Loss', f'{history[\"val_loss\"][-1]:.4f}'],\n",
    "        ['Total Epochs Trained', f'{len(epochs)}'],\n",
    "        ['Best Epoch', f'{best_epoch}'],\n",
    "        ['Final Learning Rate', f'{history[\"learning_rates\"][-1]:.2e}']\n",
    "    ]\n",
    "    \n",
    "    table = ax5.table(cellText=stats_data[1:], colLabels=stats_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.3, 0.2])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style the table\n",
    "    for i in range(len(stats_data)):\n",
    "        for j in range(2):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # Header\n",
    "                cell.set_facecolor('#4472C4')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#F2F2F2' if i % 2 == 0 else 'white')\n",
    "            cell.set_edgecolor('white')\n",
    "            cell.set_linewidth(2)\n",
    "    \n",
    "    # Add title\n",
    "    fig.suptitle('ResNet-18 Emotion Recognition Training Results', \n",
    "                fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(CONFIG['save_dir'], 'training_results.png'), \n",
    "                dpi=300, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "# Create visualization\n",
    "create_training_plots(training_history, best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d8cf7",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "checkpoint = torch.load(os.path.join(CONFIG['save_dir'], 'best_resnet_model.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Final evaluation\n",
    "final_val_loss, final_val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"Final Training Accuracy: {training_history['train_acc'][-1]:.2f}%\")\n",
    "print(f\"Final Training Loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Total Epochs: {len(training_history['train_loss'])}\")\n",
    "\n",
    "# GPU Memory usage\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    cached = torch.cuda.memory_reserved() / 1024**3\n",
    "    print(f\"\\nGPU Memory Usage:\")\n",
    "    print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Cached: {cached:.2f} GB\")\n",
    "\n",
    "print(f\"\\nModel saved to: {CONFIG['save_dir']}/best_resnet_model.pth\")\n",
    "print(f\"Visualization saved to: {CONFIG['save_dir']}/training_results.png\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Evaluate on test dataset\")\n",
    "print(\"  2. Generate confusion matrix\")\n",
    "print(\"  3. Implement inference pipeline\")\n",
    "print(\"  4. Deploy for real-time emotion detection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
