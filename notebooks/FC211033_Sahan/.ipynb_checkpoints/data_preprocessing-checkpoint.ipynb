{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Detection Preprocessing Notebook\n",
    "# ResNet-18 Architecture for 48x48 Grayscale Images\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "from collections import Counter\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Setup Complete!\n",
      "PyTorch Version: 2.1.0+cu121\n",
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "#CONFIG\n",
    "\n",
    "CONFIG = {\n",
    "    # Directory paths\n",
    "    'dataset_root': '../../data/raw/fer2013/train',\n",
    "    'train_dir': '../../data/raw/fer2013/train',\n",
    "    'test_dir': '../../data/raw/fer2013/test',\n",
    "    'output_dir': '../../data/processed_data',\n",
    "    'model_save_dir': '../../models',\n",
    "    \n",
    "    # Dataset parameters\n",
    "    'image_size': (48, 48),\n",
    "    'batch_size': 32,\n",
    "    'validation_split': 0.2,\n",
    "    'test_split': 0.1,\n",
    "    \n",
    "    # Training parameters\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 10,\n",
    "    \n",
    "    # Emotion labels\n",
    "    'emotion_labels': ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "}\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Create output directories\n",
    "for dir_path in [CONFIG['output_dir'], CONFIG['model_save_dir']]:\n",
    "    os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc023125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EFFICIENT DATASET CLASS (No EDA)\n",
    "# =============================================================================\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "        # Load images from directory structure\n",
    "        for emotion in CONFIG['emotion_labels']:\n",
    "            emotion_dir = os.path.join(data_dir, emotion)\n",
    "            if os.path.exists(emotion_dir):\n",
    "                for img_file in os.listdir(emotion_dir):\n",
    "                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        img_path = os.path.join(emotion_dir, img_file)\n",
    "                        self.data.append(img_path)\n",
    "                        self.labels.append(emotion)\n",
    "        \n",
    "        # Encode labels\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        print(f\"Loaded {len(self.data)} images across {len(self.label_encoder.classes_)} classes\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        self.print_class_distribution()\n",
    "    \n",
    "    def print_class_distribution(self):\n",
    "        \"\"\"Print and visualize class distribution\"\"\"\n",
    "        class_counts = Counter(self.labels)\n",
    "        print(\"\\nClass Distribution:\")\n",
    "        for i, class_name in enumerate(self.label_encoder.classes_):\n",
    "            count = class_counts[i]\n",
    "            percentage = (count / len(self.labels)) * 100\n",
    "            print(f\"{class_name}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Calculate class weights for handling imbalanced dataset\"\"\"\n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(self.labels),\n",
    "            y=self.labels\n",
    "        )\n",
    "        return torch.FloatTensor(class_weights)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # Convert to grayscale if needed\n",
    "        if image.mode != 'L':\n",
    "            image = image.convert('L')\n",
    "        \n",
    "        # Resize if needed\n",
    "        if image.size != CONFIG['image_size']:\n",
    "            image = image.resize(CONFIG['image_size'])\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cd182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTIMIZED TRANSFORMS (No Resize Needed)\n",
    "# =============================================================================\n",
    "class TransformedDataset(Dataset):\n",
    "    \"\"\"Wrapper to apply specific transforms to dataset subsets\"\"\"\n",
    "    def __init__(self, dataset, indices, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        img_path = self.dataset.data[actual_idx]\n",
    "        label = self.dataset.labels[actual_idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path)\n",
    "        if image.mode != 'L':\n",
    "            image = image.convert('L')\n",
    "        if image.size != CONFIG['image_size']:\n",
    "            image = image.resize(CONFIG['image_size'])\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_statistics(dataset):\n",
    "    \"\"\"Calculate mean and std of the dataset\"\"\"\n",
    "    print(\"Calculating dataset statistics...\")\n",
    "    \n",
    "    # Create a simple transform to convert to tensor\n",
    "    temp_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    # Calculate statistics\n",
    "    pixel_sum = 0\n",
    "    pixel_squared_sum = 0\n",
    "    num_pixels = 0\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        img_path = dataset.data[i]\n",
    "        image = Image.open(img_path)\n",
    "        if image.mode != 'L':\n",
    "            image = image.convert('L')\n",
    "        if image.size != CONFIG['image_size']:\n",
    "            image = image.resize(CONFIG['image_size'])\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image_tensor = temp_transform(image)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        pixel_sum += image_tensor.sum()\n",
    "        pixel_squared_sum += (image_tensor ** 2).sum()\n",
    "        num_pixels += image_tensor.numel()\n",
    "    \n",
    "    mean = pixel_sum / num_pixels\n",
    "    std = torch.sqrt(pixel_squared_sum / num_pixels - mean ** 2)\n",
    "    \n",
    "    print(f\"Dataset statistics - Mean: {mean:.4f}, Std: {std:.4f}\")\n",
    "    return mean.item(), std.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(mean=None, std=None):\n",
    "    \"\"\"Get transforms with proper normalization\"\"\"\n",
    "    # Use calculated statistics or default values\n",
    "    if mean is None or std is None:\n",
    "        mean, std = 0.485, 0.229  # Default ImageNet values\n",
    "    \n",
    "    # Training transforms with augmentation\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[mean], std=[std])\n",
    "    ])\n",
    "    \n",
    "    # Validation/Test transforms\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[mean], std=[std])\n",
    "    ])\n",
    "    \n",
    "    return train_transforms, val_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionResNet(nn.Module):\n",
    "    def __init__(self, num_classes=7, pretrained=True, dropout_rate=0.5):\n",
    "        super(EmotionResNet, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet-18\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Modify first layer for grayscale input\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Modify final layer for emotion classification\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate * 0.6),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize the new conv1 layer\n",
    "        nn.init.kaiming_normal_(self.resnet.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f09ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(dataset, num_samples=16):\n",
    "    \"\"\"Visualize sample images from each class\"\"\"\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(20, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Get samples from each class\n",
    "    class_samples = {}\n",
    "    for i, label in enumerate(dataset.labels):\n",
    "        if label not in class_samples:\n",
    "            class_samples[label] = []\n",
    "        if len(class_samples[label]) < 2:\n",
    "            class_samples[label].append(i)\n",
    "    \n",
    "    # Display samples\n",
    "    idx = 0\n",
    "    for class_idx, class_name in enumerate(dataset.label_encoder.classes_):\n",
    "        if class_idx in class_samples:\n",
    "            for sample_idx in class_samples[class_idx]:\n",
    "                if idx < 16:\n",
    "                    img_path = dataset.data[sample_idx]\n",
    "                    image = Image.open(img_path)\n",
    "                    if image.mode != 'L':\n",
    "                        image = image.convert('L')\n",
    "                    \n",
    "                    axes[idx].imshow(image, cmap='gray')\n",
    "                    axes[idx].set_title(f'{class_name}', fontsize=10)\n",
    "                    axes[idx].axis('off')\n",
    "                    idx += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CONFIG['output_dir'], 'sample_images.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_distribution(dataset):\n",
    "    \"\"\"Plot class distribution\"\"\"\n",
    "    class_counts = Counter(dataset.labels)\n",
    "    classes = [dataset.label_encoder.classes_[i] for i in range(len(dataset.label_encoder.classes_))]\n",
    "    counts = [class_counts[i] for i in range(len(dataset.label_encoder.classes_))]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(classes, counts, color='steelblue', alpha=0.7)\n",
    "    plt.title('Class Distribution in Dataset', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Emotion Classes', fontsize=12)\n",
    "    plt.ylabel('Number of Images', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "                str(count), ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CONFIG['output_dir'], 'class_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EMOTION DETECTION PREPROCESSING\n",
      "==================================================\n",
      "Creating data loaders...\n",
      "Loaded 0 images across 0 classes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.30000000000000004 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# USAGE EXAMPLE\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Example usage after running main():\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    # Get the preprocessed components\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    train_loader = results['train_loader']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    # Your training code goes here...\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create data loaders\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m train_loader, val_loader, test_loader, dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_data_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Initialize model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model, device \u001b[38;5;241m=\u001b[39m initialize_model()\n",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m, in \u001b[0;36mcreate_data_loaders\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m EmotionDataset(CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_root\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create data splits\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_idx, temp_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation_split\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_split\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m val_idx, test_idx \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     21\u001b[0m     temp_idx,\n\u001b[1;32m     22\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_split\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_split\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_split\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     23\u001b[0m     stratify\u001b[38;5;241m=\u001b[39m[dataset\u001b[38;5;241m.\u001b[39mlabels[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m temp_idx], random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData splits - Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2277\u001b[0m     )\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.30000000000000004 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "def create_data_loaders():\n",
    "    \"\"\"Create train/validation/test data loaders with proper transforms\"\"\"\n",
    "    \n",
    "    print(\"Creating data loaders...\")\n",
    "    \n",
    "    # Load dataset\n",
    "    full_dataset = EmotionDataset(CONFIG['dataset_root'])\n",
    "    \n",
    "    # Calculate dataset statistics\n",
    "    mean, std = calculate_dataset_statistics(full_dataset)\n",
    "    \n",
    "    # Create data splits\n",
    "    train_idx, temp_idx = train_test_split(\n",
    "        range(len(full_dataset)), \n",
    "        test_size=CONFIG['validation_split'] + CONFIG['test_split'],\n",
    "        stratify=full_dataset.labels, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx,\n",
    "        test_size=CONFIG['test_split'] / (CONFIG['validation_split'] + CONFIG['test_split']),\n",
    "        stratify=[full_dataset.labels[i] for i in temp_idx], \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Data splits - Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "    \n",
    "    # Get transforms with calculated statistics\n",
    "    train_transforms, val_transforms = get_transforms(mean, std)\n",
    "    \n",
    "    # Create transformed datasets\n",
    "    train_dataset = TransformedDataset(full_dataset, train_idx, train_transforms)\n",
    "    val_dataset = TransformedDataset(full_dataset, val_idx, val_transforms)\n",
    "    test_dataset = TransformedDataset(full_dataset, test_idx, val_transforms)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CONFIG['batch_size'], \n",
    "        shuffle=True, \n",
    "        num_workers=4, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, \n",
    "        num_workers=4, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, \n",
    "        num_workers=4, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, full_dataset, mean, std\n",
    "\n",
    "def setup_model_and_training():\n",
    "    \"\"\"Setup model and training components\"\"\"\n",
    "    \n",
    "    print(\"Setting up model and training components...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = EmotionResNet(num_classes=len(CONFIG['emotion_labels']))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Model summary\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    return model, device\n",
    "\n",
    "def save_preprocessing_info(dataset, train_size, val_size, test_size, mean, std, class_weights):\n",
    "    \"\"\"Save preprocessing information\"\"\"\n",
    "    \n",
    "    preprocessing_info = {\n",
    "        'dataset_size': len(dataset),\n",
    "        'train_size': train_size,\n",
    "        'val_size': val_size,\n",
    "        'test_size': test_size,\n",
    "        'num_classes': len(CONFIG['emotion_labels']),\n",
    "        'emotion_labels': CONFIG['emotion_labels'],\n",
    "        'label_encoder_classes': dataset.label_encoder.classes_.tolist(),\n",
    "        'image_size': CONFIG['image_size'],\n",
    "        'batch_size': CONFIG['batch_size'],\n",
    "        'dataset_statistics': {\n",
    "            'mean': mean,\n",
    "            'std': std\n",
    "        },\n",
    "        'class_weights': class_weights.tolist(),\n",
    "        'config': CONFIG\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(CONFIG['output_dir'], 'preprocessing_info.json'), 'w') as f:\n",
    "        json.dump(preprocessing_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Preprocessing info saved to: {os.path.join(CONFIG['output_dir'], 'preprocessing_info.json')}\")\n",
    "    return preprocessing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main preprocessing pipeline execution\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"EMOTION DETECTION PREPROCESSING - ENHANCED VERSION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader, dataset, mean, std = create_data_loaders()\n",
    "    \n",
    "    # Setup model\n",
    "    model, device = setup_model_and_training()\n",
    "    \n",
    "    # Get class weights for handling imbalanced dataset\n",
    "    class_weights = dataset.get_class_weights()\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    # Visualize data\n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    plot_class_distribution(dataset)\n",
    "    visualize_sample_images(dataset)\n",
    "    \n",
    "    # Save preprocessing information\n",
    "    preprocessing_info = save_preprocessing_info(\n",
    "        dataset, \n",
    "        len(train_loader.dataset), \n",
    "        len(val_loader.dataset), \n",
    "        len(test_loader.dataset),\n",
    "        mean, \n",
    "        std,\n",
    "        class_weights\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Dataset size: {len(dataset)} images\")\n",
    "    print(f\"Classes: {len(CONFIG['emotion_labels'])}\")\n",
    "    print(f\"Dataset statistics: Mean={mean:.4f}, Std={std:.4f}\")\n",
    "    print(\"Ready for training!\")\n",
    "    \n",
    "    return {\n",
    "        'train_loader': train_loader,\n",
    "        'val_loader': val_loader,\n",
    "        'test_loader': test_loader,\n",
    "        'model': model,\n",
    "        'device': device,\n",
    "        'class_weights': class_weights,\n",
    "        'dataset_stats': {'mean': mean, 'std': std},\n",
    "        'preprocessing_info': preprocessing_info\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30459ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = main()\n",
    "    \n",
    "    # Now you can use the results for training:\n",
    "    # train_loader = results['train_loader']\n",
    "    # val_loader = results['val_loader']\n",
    "    # test_loader = results['test_loader']\n",
    "    # model = results['model']\n",
    "    # device = results['device']\n",
    "    # class_weights = results['class_weights']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
