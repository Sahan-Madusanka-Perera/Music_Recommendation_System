{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e67fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Facial Emotion Detection for Music Recommendation System\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Merges FER-2013 classes into 5 target emotions\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# imports and setups\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6319944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train and test data paths\n",
    "base_dir = '../../data/raw/fer2013/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Emotion class configuration\n",
    "original_classes = ['angry', 'disgust', 'fear',\n",
    "                    'happy', 'sad', 'surprise', 'neutral']\n",
    "target_classes = ['happy', 'sad', 'angry', 'stressed', 'neutral']\n",
    "\n",
    "class_mapping = {\n",
    "    'angry': 'angry',\n",
    "    'disgust': 'angry',      # Merge disgust into angry\n",
    "    'fear': 'stressed',      # Map fear to stressed\n",
    "    'happy': 'happy',\n",
    "    'sad': 'sad',\n",
    "    'surprise': 'neutral',   # Map surprise to neutral\n",
    "    'neutral': 'neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data generating\n",
    "class MergedDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def flow_from_directory(self, directory, **kwargs):\n",
    "        generator = super().flow_from_directory(\n",
    "            directory,\n",
    "            target_size=(48, 48),\n",
    "            color_mode='grayscale',\n",
    "            class_mode='categorical',\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            x_batch, y_batch = next(generator)\n",
    "            y_merged = np.zeros((y_batch.shape[0], 5))\n",
    "\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                original_class = np.argmax(y_batch[i])\n",
    "                original_name = original_classes[original_class]\n",
    "                target_name = class_mapping[original_name]\n",
    "                target_index = target_classes.index(target_name)\n",
    "                y_merged[i, target_index] = 1\n",
    "\n",
    "            yield x_batch, y_merged\n",
    "\n",
    "\n",
    "# Initialize generators\n",
    "train_datagen = MergedDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = MergedDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b31f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        # Block 1\n",
    "        Conv2D(64, (3, 3), activation='relu',\n",
    "               padding='same', input_shape=(48, 48, 1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Block 2\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Block 3\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Classifier\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "def train_model(model, train_gen, test_gen):\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=train_gen.samples // train_gen.batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=test_gen,\n",
    "        validation_steps=test_gen.samples // test_gen.batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "history = train_model(model, train_generator, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13eb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "def evaluate_model(model, test_gen):\n",
    "    test_gen.reset()\n",
    "    y_pred = model.predict(test_gen)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    y_true = []\n",
    "    for i in range(len(test_gen)):\n",
    "        _, labels = test_gen[i]\n",
    "        y_true.extend(np.argmax(labels, axis=1))\n",
    "    y_true = np.array(y_true)[:len(y_pred_classes)]\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=target_classes))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_classes,\n",
    "                yticklabels=target_classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "evaluate_model(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a456a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Time emotion detection\n",
    "def real_time_emotion_detection(model):\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            try:\n",
    "                face_roi = gray[y:y+h, x:x+w]\n",
    "                resized = cv2.resize(face_roi, (48, 48))\n",
    "                normalized = resized / 255.0\n",
    "                reshaped = normalized.reshape(1, 48, 48, 1)\n",
    "\n",
    "                pred = model.predict(reshaped, verbose=0)\n",
    "                emotion_idx = np.argmax(pred)\n",
    "                confidence = np.max(pred)\n",
    "\n",
    "                if confidence > 0.7:\n",
    "                    emotion = target_classes[emotion_idx]\n",
    "                    label = f\"{emotion} ({confidence:.2f})\"\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, label, (x, y-10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            except Exception as e:\n",
    "                print(f\"Processing error: {e}\")\n",
    "                continue\n",
    "\n",
    "        cv2.imshow('Emotion Detection', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05040544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "def save_model(model, filename='emotion_detection_5class.h5'):\n",
    "    model.save(filename)\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "\n",
    "save_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
