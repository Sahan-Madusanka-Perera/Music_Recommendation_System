{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6594b08-7206-4564-9647-58f2715c0d2c",
   "metadata": {},
   "source": [
    "# Data Cleaning & Split  - EfficientNet B0\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "    Data Cleaning\n",
    "\n",
    "        - Load raw data directories for train and test splits.\n",
    "        - For each image in the dataset:\n",
    "            - verify cropped and Read the image in grayscale.\n",
    "            - Check and handle  corrpted , unreadable ,dupicates images[Uses MD5 hashing]\n",
    "            - Verify image size is exactly 48×48 pixels.\n",
    "            - Quality metrics: Dark/bright/contrast/blur thresholds from EDA\n",
    "            - Robust filtering: Rejects images with 2+ quality issues\n",
    "----------------------------------------\n",
    "\n",
    "    Data Split\n",
    "\n",
    "\n",
    "        - Split the training data into training and validation sets , stratified by class to maintain class proportions.\n",
    "        - Keep the test split untouched \n",
    "----------------------------------------        \n",
    "    \n",
    "        - Save processed datasets (images and labels) as compressed .npz files (train.npz, val.npz, test.npz).ed)\n",
    "        \n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8d15a2-31f8-420c-a09d-f3b40b1405a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155e42a-8c77-46f2-8636-a0245632f118",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7487245a-3897-4b32-aa39-2b199d900078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "RAW_DIR= Path(\"/app/data/raw/fer2013\")\n",
    "PROCESSED_DIR = Path(\"/app/data/processed/FC211002_Nethmi\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a8faeb-5f92-48a8-9932-0a7455b60608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality thresholds (from EDA)\n",
    "DARK_THRESHOLD = 50\n",
    "BRIGHT_THRESHOLD = 200\n",
    "LOW_CONTRAST_THRESHOLD = 15\n",
    "BLUR_THRESHOLD = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16003ef-3581-4a5f-b624-1a1072b4c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data directory: /app/data/raw/fer2013\n",
      "Processed data directory: /app/data/processed/FC211002_Nethmi\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw data directory: {RAW_DIR}\")\n",
    "print(f\"Processed data directory: {PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53fd6e-2979-41a2-94cb-5bac170aed9b",
   "metadata": {},
   "source": [
    "## 2.Class Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1a970d-c1eb-4cc6-b08b-09a2f63c46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping FER2013 classes to 5 project classes\n",
    "emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "CLASS_MAPPING = {\n",
    "    'angry': 'angry',\n",
    "    'disgust': 'angry',\n",
    "    'fear': 'stressed',\n",
    "    'surprise': 'stressed',\n",
    "    'happy': 'happy',\n",
    "    'neutral': 'neutral',\n",
    "    'sad': 'sad'\n",
    "}\n",
    "TARGET_CLASSES = ['angry', 'happy', 'sad', 'stressed', 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc1c83-456b-4d48-8ab7-baf7aa992ae9",
   "metadata": {},
   "source": [
    "## 3.Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd748fdc-0822-4fc3-a130-c7529f62f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Generate MD5 hash for duplicate detection\n",
    "def get_image_hash(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "#Check image quality metrics\n",
    "#Check image for \n",
    "    # brightness (too dark or too bright)\n",
    "    # contrast (too low)\n",
    "    # blur\n",
    "def check_image_quality(image):\n",
    "    mean_pixel = np.mean(image)\n",
    "    contrast = np.std(image)\n",
    "    blur_score = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    \n",
    "    quality_issues = 0\n",
    "    if mean_pixel < DARK_THRESHOLD: quality_issues += 1\n",
    "    if mean_pixel > BRIGHT_THRESHOLD: quality_issues += 1\n",
    "    if contrast < LOW_CONTRAST_THRESHOLD: quality_issues += 1\n",
    "    if blur_score < BLUR_THRESHOLD: quality_issues += 1\n",
    "    \n",
    "    return quality_issues >= 2  # Reject if 2+ issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf9831b-ec86-46d4-a115-c5314ce5dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General cleaning function for train/test sets \n",
    "# Clean  (basic cleaning only, no quality removal yet) \n",
    "def process_data(split_name, remove_quality=False):\n",
    "   \n",
    "    print(f\"\\nProcessing {split_name.upper()} set...\")\n",
    "    \n",
    "    split_dir = RAW_DIR / split_name\n",
    "    cleaned_images, cleaned_labels = [], []  # lists to store valid images and labels\n",
    "    stats = {k:0 for k in ['total_files','valid_images','duplicates','corrupted','wrong_size','poor_quality','read_errors']}\n",
    "    seen_hashes = set()  # to track duplicates\n",
    "    \n",
    "    # Map original folders to TARGET_CLASSES\n",
    "    mapped_dirs = {cls: [] for cls in TARGET_CLASSES}\n",
    "    for orig_dir in split_dir.iterdir():\n",
    "        if orig_dir.is_dir() and orig_dir.name in CLASS_MAPPING:\n",
    "            mapped_dirs[CLASS_MAPPING[orig_dir.name]].append(orig_dir)\n",
    "    \n",
    "    # Iterate over each mapped class\n",
    "    for cls in TARGET_CLASSES:\n",
    "        for folder in mapped_dirs[cls]:\n",
    "            # Get all images in folder\n",
    "            image_files = list(folder.glob(\"*.jpg\")) + list(folder.glob(\"*.png\"))\n",
    "            for img_path in image_files:\n",
    "                stats['total_files'] += 1\n",
    "                try:\n",
    "                    # Duplicate check \n",
    "                    img_hash = get_image_hash(img_path)\n",
    "                    if img_hash in seen_hashes:\n",
    "                        stats['duplicates'] += 1\n",
    "                        continue\n",
    "                    seen_hashes.add(img_hash)\n",
    "\n",
    "                    # Read grayscale image \n",
    "                    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is None:  # corrupted/unreadable\n",
    "                        stats['corrupted'] += 1\n",
    "                        continue\n",
    "\n",
    "                    # Size check \n",
    "                    if img.shape != (48,48):\n",
    "                        stats['wrong_size'] += 1\n",
    "                        continue\n",
    "\n",
    "                    # Poor-quality check \n",
    "                    # Only applied if remove_quality=True \n",
    "                    if remove_quality and check_image_quality(img):\n",
    "                        stats['poor_quality'] += 1\n",
    "                        continue\n",
    "\n",
    "                    # Passed all checks : store image and label\n",
    "                    cleaned_images.append(img)\n",
    "                    cleaned_labels.append(TARGET_CLASSES.index(cls))\n",
    "                    stats['valid_images'] += 1\n",
    "\n",
    "                except:\n",
    "                    stats['read_errors'] += 1\n",
    "\n",
    "    # Summary of cleaning\n",
    "    print(f\"\\n{split_name.upper()} CLEANING SUMMARY:\")\n",
    "    print(f\"  Total files processed: {stats['total_files']}\")\n",
    "    print(f\"  Valid images: {stats['valid_images']} ({stats['valid_images']/stats['total_files']*100:.1f}%)\")\n",
    "    print(f\"  Issues removed:\")\n",
    "    print(f\"    - Duplicates:        {stats['duplicates']}\")\n",
    "    print(f\"    - Corrupted:         {stats['corrupted']}\")\n",
    "    print(f\"    - Wrong size:        {stats['wrong_size']}\")\n",
    "    print(f\"    - Poor quality:      {stats['poor_quality']}\")\n",
    "    print(f\"    - Read errors:       {stats['read_errors']}\")\n",
    "    \n",
    "    return np.array(cleaned_images), np.array(cleaned_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dca27c0-40bf-4949-b146-f4e60e225b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing TRAIN set...\n",
      "\n",
      "TRAIN CLEANING SUMMARY:\n",
      "  Total files processed: 28709\n",
      "  Valid images: 27473 (95.7%)\n",
      "  Issues removed:\n",
      "    - Duplicates:        1236\n",
      "    - Corrupted:         0\n",
      "    - Wrong size:        0\n",
      "    - Poor quality:      0\n",
      "    - Read errors:       0\n",
      "\n",
      "Processing TEST set...\n",
      "\n",
      "TEST CLEANING SUMMARY:\n",
      "  Total files processed: 7178\n",
      "  Valid images: 7092 (98.8%)\n",
      "  Issues removed:\n",
      "    - Duplicates:        86\n",
      "    - Corrupted:         0\n",
      "    - Wrong size:        0\n",
      "    - Poor quality:      0\n",
      "    - Read errors:       0\n"
     ]
    }
   ],
   "source": [
    "# Clean both train and test sets\n",
    "train_images, train_labels = process_data('train', remove_quality=False)\n",
    "test_images, test_labels   = process_data('test', remove_quality=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2c530-0e45-4711-9e98-40791b51733d",
   "metadata": {},
   "source": [
    "## 4.Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01720aa-12ba-48bb-a414-9f0c886bbf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train → train + val \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46849cf-432f-4451-ac35-48c7271e7ed8",
   "metadata": {},
   "source": [
    "## 5. Remove Poor Quality Images from Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326afdb6-c0f5-483a-bb5e-7e051922e555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL DATASETS:\n",
      "  Training:   21970 images (poor-quality images removed)\n",
      "  Validation: 5495 images (unchanged)\n",
      "  Test:       7092 images (unchanged)\n"
     ]
    }
   ],
   "source": [
    "#  Remove poor-quality images only from training set \n",
    "def remove_poor_quality(images, labels):\n",
    "    \n",
    "    keep_images, keep_labels = [], []\n",
    "    for img, lbl in zip(images, labels):\n",
    "        if not check_image_quality(img):  # keep only good-quality images\n",
    "            keep_images.append(img)\n",
    "            keep_labels.append(lbl)\n",
    "    return np.array(keep_images), np.array(keep_labels)\n",
    "\n",
    "X_train, y_train = remove_poor_quality(X_train, y_train)\n",
    "\n",
    "#  Summary of final datasets \n",
    "print(f\"\\nFINAL DATASETS:\")\n",
    "print(f\"  Training:   {len(X_train)} images (poor-quality images removed)\")\n",
    "print(f\"  Validation: {len(X_val)} images (unchanged)\")\n",
    "print(f\"  Test:       {len(test_images)} images (unchanged)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194e97c-9155-4f40-921a-39adf9871fe3",
   "metadata": {},
   "source": [
    "## 6.Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73f15a54-874f-4d5f-853a-24cbb040d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASS DISTRIBUTION AFTER CLEANING:\n",
      "Class      Train        Val          Test        \n",
      "angry      3383 ( 15.4%) 846 ( 15.4%) 1055 ( 14.9%)\n",
      "happy      5668 ( 25.8%) 1417 ( 25.8%) 1767 ( 24.9%)\n",
      "sad        3779 ( 17.2%) 945 ( 17.2%) 1241 ( 17.5%)\n",
      "stressed   5250 ( 23.9%) 1313 ( 23.9%) 1804 ( 25.4%)\n",
      "neutral    3890 ( 17.7%) 974 ( 17.7%) 1225 ( 17.3%)\n",
      "-----------------------------------------------------------------\n",
      "Total      21970 (100.0%) 5495 (100.0%) 7092 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Class Distribution Display \n",
    "from collections import Counter\n",
    "\n",
    "def display_class_distribution(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \n",
    "    print(\"\\nCLASS DISTRIBUTION AFTER CLEANING:\")\n",
    "    # print(\"=\"*65)\n",
    "    \n",
    "    train_dist, val_dist, test_dist = Counter(y_train), Counter(y_val), Counter(y_test)\n",
    "    total_train, total_val, total_test = len(y_train), len(y_val), len(y_test)\n",
    "    \n",
    "    print(f\"{'Class':<10} {'Train':<12} {'Val':<12} {'Test':<12}\")\n",
    "    \n",
    "    for i, cls in enumerate(TARGET_CLASSES):\n",
    "        tr_count = train_dist[i]\n",
    "        val_count = val_dist[i]\n",
    "        te_count = test_dist[i]\n",
    "        print(f\"{cls:<10} {tr_count} ({tr_count/total_train*100:5.1f}%) \"\n",
    "              f\"{val_count} ({val_count/total_val*100:5.1f}%) \"\n",
    "              f\"{te_count} ({te_count/total_test*100:5.1f}%)\")\n",
    "    \n",
    "    # Print totals\n",
    "    print(f\"{'-'*65}\")\n",
    "    print(f\"{'Total':<10} {total_train} ({100:5.1f}%) \"\n",
    "          f\"{total_val} ({100:5.1f}%) \"\n",
    "          f\"{total_test} ({100:5.1f}%)\")\n",
    "\n",
    "# Call the function after cleaning and splitting \n",
    "display_class_distribution(X_train, y_train, X_val, y_val, test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bcbf1e-112d-45f5-9e70-3ca16f159997",
   "metadata": {},
   "source": [
    "## 7.Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "708f1a95-e3f1-4f9e-9689-3e3ad492a49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed datasets saved as train.npz, val.npz, test.npz\n"
     ]
    }
   ],
   "source": [
    "# Ensure processed directory exists\n",
    "PROCESSED_DIR = Path(\"/app/data/processed/FC211002_Nethmi\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save train set\n",
    "np.savez_compressed(PROCESSED_DIR / \"train.npz\", images=X_train, labels=y_train)\n",
    "\n",
    "# Save validation set\n",
    "np.savez_compressed(PROCESSED_DIR / \"val.npz\", images=X_val, labels=y_val)\n",
    "\n",
    "# Save test set (unchanged)\n",
    "np.savez_compressed(PROCESSED_DIR / \"test.npz\", images=test_images, labels=test_labels)\n",
    "\n",
    "print(\"Processed datasets saved as train.npz, val.npz, test.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
