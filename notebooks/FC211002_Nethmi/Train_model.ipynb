{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52dd9659-65d3-4747-8f34-bb7606361dad",
   "metadata": {},
   "source": [
    "**Music Recommendation System: Emotion Detection Model Training**\n",
    "\n",
    "  - Emotion Detection: EfficientNetB0 CNN trained on FER-2013 dataset\n",
    "  - User Activity Input: 5 activities (Studying, Working, Relaxing, Exercising, Commuting)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc905a38-aa8a-45c2-8832-2f01f45f9f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 13:38:07.196682: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-15 13:38:07.198811: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-15 13:38:07.241519: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-15 13:38:07.243302: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-15 13:38:08.534239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb99d6-7a04-49db-83e3-ecae19a09ace",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd84631-be62-4884-a81a-26300c87852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: []\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1695c067-858a-43a4-9696-df0e4afa66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "#Forces TensorFlow to use only CPU, preventing GPU memory issues\n",
    "#Disables GPU visibility to ensure CPU-only training\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable GPU\n",
    "tf.config.set_visible_devices([], 'GPU')    # Ensure no GPU devices are visible\n",
    "\n",
    "# System information\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Available devices: {tf.config.list_physical_devices()}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698f98ad-7079-416e-b64d-c8db8655a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "BASE_DIR = Path(\"/app\")\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"processed\" / \"FC211002_Nethmi\"   # path to processed dataset\n",
    "TRAIN_DIR = DATA_DIR / \"train\"\n",
    "VAL_DIR = DATA_DIR / \"test\"\n",
    "\n",
    "MODEL_DIR = BASE_DIR / \"model\" / \"FC211002_Nethmi\"   # Output model directory\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3b59e2-53a5-4059-ba76-d7bcf2a3b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "IMG_SIZE = (48, 48) #processed images are 48x48\n",
    "BATCH_SIZE = 32  # Small batch size for CPU training efficiency\n",
    "EPOCHS = 20\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "CLASS_NAMES = ['angry', 'happy', 'sad', 'stressed', 'neutral']\n",
    "\n",
    "LEARNING_RATE = 0.001  # learning rate for Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1527be33-819f-45d1-a1d3-8dbf9e23e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "Data directory: /app/data/processed/FC211002_Nethmi\n",
      "Model directory: /app/model/FC211002_Nethmi\n",
      "Image size: (48, 48)\n",
      "Number of classes: 5\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5ffa2-78ab-4583-b422-fc23f0524c0f",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2ce7c-a652-4416-b4aa-d3088ad2bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators():\n",
    "    \n",
    "    \n",
    "    # Training data generator with augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255.0,           # Normalize pixel values to [0,1]\n",
    "        rotation_range=20,           # Random rotation up to 20 degrees\n",
    "        width_shift_range=0.1,       # Random horizontal shift\n",
    "        height_shift_range=0.1,      # Random vertical shift\n",
    "        horizontal_flip=True,        # Random horizontal flip\n",
    "        zoom_range=0.1,             # Random zoom in/out\n",
    "        validation_split=0.2         # Reserve 20% for validation\n",
    "    )\n",
    "    \n",
    "    # Validation data generator (no augmentation)\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255.0,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Load training data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        DATA_DIR / \"train\",\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',    # One-hot encoded labels\n",
    "        subset='training',           # Use 80% for training\n",
    "        shuffle=True,               # Shuffle data for better training\n",
    "        color_mode='rgb'            # RGB images (3 channels)\n",
    "    )\n",
    "    \n",
    "    # Load validation data\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        DATA_DIR / \"train\",          # Use same directory but different subset\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',         # Use 20% for validation\n",
    "        shuffle=False,              # Don't shuffle validation data\n",
    "        color_mode='rgb'\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
