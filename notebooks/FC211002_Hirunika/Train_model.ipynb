{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870094c-2d64-471e-8413-eae0d21bb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e0c0b-b1dc-402e-bfb6-5ede7f4d203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "BASE_DIR = Path(\"/app/data/processed/FC211002_Hirunika\")\n",
    "TRAIN_DIR = BASE_DIR / \"train\"\n",
    "VAL_DIR = BASE_DIR / \"test\"\n",
    "MODEL_SAVE_DIR = Path(\"/app/model/FC211002_Hirunika\")\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43660a-84c2-412b-a5f7-896ee50e8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "NUM_CLASSES = 5\n",
    "CLASS_NAMES = ['angry', 'happy', 'sad', 'stressed', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9206fb-1e07-4c3b-9bdf-5a38212cb355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Class Weights (for imbalance)\n",
    "class_counts = {\n",
    "    'angry': 3995 + 436,\n",
    "    'stressed': 4097 + 3171,\n",
    "    'happy': 7215,\n",
    "    'neutral': 4965,\n",
    "    'sad': 4830\n",
    "}\n",
    "total_images = sum(class_counts.values())\n",
    "\n",
    "class_weights = {\n",
    "    i: total_images / (NUM_CLASSES * count)\n",
    "    for i, count in enumerate([class_counts[cls] for cls in TARGET_CLASSES])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b56e9-c37c-4461-a388-6a000f2e3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=str(TRAIN_DIR),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory=str(VAL_DIR),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2297689-c818-4ba1-bce2-9e85835b8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNetB0 from Scratch\n",
    "# def build_efficientnetb0(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES):\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "#     # Stem\n",
    "#     x = layers.Conv2D(32, 3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation('swish')(x)\n",
    "\n",
    "#     # MBConv block\n",
    "#     def mbconv_block(x, filters, kernel_size, strides, expansion):\n",
    "#         shortcut = x\n",
    "#         x = layers.Conv2D(filters * expansion, 1, padding='same', use_bias=False)(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.Activation('swish')(x)\n",
    "\n",
    "#         x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=False)(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.Activation('swish')(x)\n",
    "\n",
    "#         x = layers.Conv2D(filters, 1, padding='same', use_bias=False)(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "\n",
    "#         if strides == 1 and shortcut.shape[-1] == filters:\n",
    "#             x = layers.Add()([x, shortcut])\n",
    "#         return x\n",
    "\n",
    "#     # EfficientNetB0 structure\n",
    "#     x = mbconv_block(x, 16, 3, 1, 1)\n",
    "#     x = mbconv_block(x, 24, 3, 2, 6)\n",
    "#     x = mbconv_block(x, 24, 3, 1, 6)\n",
    "#     x = mbconv_block(x, 40, 5, 2, 6)\n",
    "#     x = mbconv_block(x, 40, 5, 1, 6)\n",
    "#     x = mbconv_block(x, 80, 3, 2, 6)\n",
    "#     x = mbconv_block(x, 80, 3, 1, 6)\n",
    "#     x = mbconv_block(x, 112, 5, 1, 6)\n",
    "#     x = mbconv_block(x, 112, 5, 1, 6)\n",
    "#     x = mbconv_block(x, 192, 3, 2, 6)\n",
    "#     x = mbconv_block(x, 192, 3, 1, 6)\n",
    "#     x = mbconv_block(x, 320, 3, 1, 6)\n",
    "\n",
    "    # # Head\n",
    "    # x = layers.Conv2D(1280, 1, padding='same', use_bias=False)(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    # x = layers.Activation('swish')(x)\n",
    "    # x = layers.GlobalAveragePooling2D()(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    # outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # return models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f14167-8856-471c-9467-41a8c8efc1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build EfficientNetB0 Model (from scratch)\n",
    "\n",
    "# Create input layer\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Build EfficientNetB0 base (no weights from ImageNet)\n",
    "base_model = EfficientNetB0(include_top=False, weights=None, input_tensor=inputs)\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cabd725-d07a-4707-a213-8b9004cfeb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "# model = build_efficientnetb0()\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "# model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8dc67-76d4-4502-b97f-fc7b51eba955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=str(MODEL_SAVE_DIR / \"efficientnetb0_model.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     str(CHECKPOINT_DIR / \"efficientnetb0_best.h5\"),\n",
    "#     save_best_only=True,\n",
    "#     monitor='val_loss',\n",
    "#     mode='min',\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# lr_scheduler_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss',\n",
    "#     factor=0.5,\n",
    "#     patience=5,\n",
    "#     min_lr=1e-6,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=10,\n",
    "#     restore_best_weights=True,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dfce3e-43fd-456f-ba7a-df098f070a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "#     validation_data=val_generator,\n",
    "#     validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "#     epochs=EPOCHS,\n",
    "#     class_weight=class_weights,\n",
    "#     callbacks=[checkpoint_cb, lr_scheduler_cb, early_stop_cb],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a8536-cc2f-4e37-b461-803aeec59905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training performance\n",
    "def plot_history(hist):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hist.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(hist.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist.history['loss'], label='Train Loss')\n",
    "    plt.plot(hist.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5cedf4-b30b-4f62-bc78-f337046fafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture & class indices\n",
    "# Save class index mapping\n",
    "import json\n",
    "with open(MODEL_SAVE_DIR / \"class_indices.json\", \"w\") as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "\n",
    "# Save model config\n",
    "model_json = model.to_json()\n",
    "with open(MODEL_SAVE_DIR / \"efficientnetb0_model.json\", \"w\") as f:\n",
    "    f.write(model_json)\n",
    "\n",
    "print(f\" Model training complete and saved to: {MODEL_SAVE_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
