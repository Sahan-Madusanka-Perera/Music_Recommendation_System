{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6f78b6-2983-4f8f-893a-4365e4a1db17",
   "metadata": {},
   "source": [
    "                      Data Preprocessing\n",
    "\n",
    "\n",
    "        \n",
    "        Optional Augmentations: \n",
    "            -Rotation: ±15 degrees (faces can be slightly tilted)\n",
    "            -Horizontal flip: ONLY for non-asymmetric emotions\n",
    "            -Brightness adjustment: ±10% (lighting variations)\n",
    "            -Small zoom: ±5% (distance variations)\n",
    "            -NO vertical flip (would create upside-down faces!)\n",
    "\n",
    "        Steps:\n",
    "    \n",
    "        \n",
    "       \n",
    "\n",
    "Total corrupted files found: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a828278a-f8fa-4be0-a787-e4b72ab4034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 20:22:01.861061: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-13 20:22:01.866729: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-13 20:22:01.932325: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-13 20:22:01.934068: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-13 20:22:02.835478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503c1231-467d-4f32-9420-89e2d31fd663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "RAW_DIR = Path(\"/app/data/raw/fer2013\")\n",
    "PROCESSED_DIR = Path(\"/app/data/processed/FC211002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336e7a6b-3720-4fa8-8827-7883c8f0e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping FER2013 (7 classes) → Project (5 classes)\n",
    "CLASS_MAPPING = {\n",
    "    'angry': 'angry',\n",
    "    'disgust': 'stressed',\n",
    "    'fear': 'stressed',\n",
    "    'happy': 'happy',\n",
    "    'sad': 'sad',\n",
    "    'surprise': 'happy',\n",
    "    'neutral': 'neutral'\n",
    "}\n",
    "\n",
    "TARGET_CLASSES = ['angry', 'happy', 'sad', 'stressed', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862469ff-a451-4be5-b096-ff623725d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder structure for processed data\n",
    "def prepare_folder_structure():\n",
    "    for split in ['train', 'test']:\n",
    "        for cls in TARGET_CLASSES:\n",
    "            out_dir = os.path.join(PROCESSED_DIR, split, cls)\n",
    "            os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff4568-921e-4a46-ab69-f29166d9e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detect duplicates using image hashing\n",
    "# def is_duplicate(img_array, seen_hashes):\n",
    "#     img_hash = hash(img_array.tobytes())\n",
    "#     if img_hash in seen_hashes:\n",
    "#         return True\n",
    "#     seen_hashes.add(img_hash)\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86982523-d6f4-4e05-85e9-874f87c93774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detect outlier images \n",
    "# def is_outlier(img_array):\n",
    "#     brightness = np.mean(img_array)\n",
    "#     contrast = np.std(img_array)\n",
    "#     return brightness < 10 or brightness > 245 or contrast < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec7c186-c1b9-48c8-a87a-74486a9c0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing with Validation\n",
    "def preprocess_image_with_checks(img_path, seen_hashes):\n",
    "    try:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            return None, \"Missing or unreadable\"\n",
    "        if img.shape != (48, 48):\n",
    "            return None, \"Incorrect size\"\n",
    "        # if is_duplicate(img, seen_hashes):\n",
    "        #     return None, \"Duplicate\"\n",
    "        # if is_outlier(img):\n",
    "        #     return None, \"Outlier\"\n",
    "\n",
    "        # Normalize and reshape\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        return img, None\n",
    "    except:\n",
    "        return None, \"Corrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff18e3a2-cb55-4abb-ad42-e98901fbbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Configuration\n",
    "augmentor = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1469f7-5d9a-49d8-b1dc-a75838309bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Preprocessing Pipeline\n",
    "def preprocess_and_save(split='train', augment=False, augment_count=2):\n",
    "    input_split_dir = os.path.join(RAW_DIR, split)\n",
    "    seen_hashes = set()\n",
    "\n",
    "    for orig_class in os.listdir(input_split_dir):\n",
    "        orig_path = os.path.join(input_split_dir, orig_class)\n",
    "        if not os.path.isdir(orig_path):\n",
    "            continue\n",
    "\n",
    "        mapped_class = CLASS_MAPPING.get(orig_class)\n",
    "        if mapped_class not in TARGET_CLASSES:\n",
    "            continue\n",
    "\n",
    "        out_class_dir = os.path.join(PROCESSED_DIR, split, mapped_class)\n",
    "        os.makedirs(out_class_dir, exist_ok=True)\n",
    "\n",
    "        image_files = [f for f in os.listdir(orig_path) if f.lower().endswith(('.png', '.jpg'))]\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(orig_path, img_file)\n",
    "            img, issue = preprocess_image_with_checks(img_path, seen_hashes)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"Skipped {img_file} — {issue}\")\n",
    "                continue\n",
    "\n",
    "            # Save preprocessed image\n",
    "            save_name = os.path.splitext(img_file)[0] + \"_pre.png\"\n",
    "            save_path = os.path.join(out_class_dir, save_name)\n",
    "            cv2.imwrite(save_path, (img.squeeze() * 255).astype(np.uint8))\n",
    "             # Augmentation\n",
    "            if augment:\n",
    "                img_batch = img.reshape((1, 48, 48, 1))\n",
    "                aug_iter = augmentor.flow(img_batch, batch_size=1)\n",
    "                for i in range(augment_count):\n",
    "                    aug_img = next(aug_iter)[0]\n",
    "                    aug_name = os.path.splitext(img_file)[0] + f\"_aug{i}.png\"\n",
    "                    aug_path = os.path.join(out_class_dir, aug_name)\n",
    "                    cv2.imwrite(aug_path, (aug_img.squeeze() * 255).astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eda032d-405d-4b27-8ca1-b8a8ae955636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All preprocessing complete. Data saved in '{PROCESSED_DIR}'\n"
     ]
    }
   ],
   "source": [
    "# Run Everything\n",
    "prepare_folder_structure()\n",
    "preprocess_and_save(split='train', augment=True, augment_count=3)   # With augmentation\n",
    "preprocess_and_save(split='test', augment=False)                    # No augmentation\n",
    "\n",
    "print(\"All preprocessing complete. Data saved in '{PROCESSED_DIR}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f953776-e489-4820-b7c2-08c76d982fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
